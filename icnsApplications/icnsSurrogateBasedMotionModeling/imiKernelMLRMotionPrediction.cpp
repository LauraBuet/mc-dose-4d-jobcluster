/** \file imiKernelMLRMotionPrediction.cpp
 *
 *  \b Initial \b Author: Matthias Wilms \n\n
 *  \b Copyright (C) 2012 Institute of Medical Informatics,
 *     University of Luebeck
 *
 *  <!----------------------------------------------------------------------->
 *  <!--  Version Information  (generated by CVS, do not change manually)  -->
 *  $Id$
 *  $Log$
 *
 ****************************************************************************/

// Project includes
#include "imiKernelMLRMotionPrediction.h"

namespace imi
{

// ----------------------------
//   Constructor / Destructor
// ----------------------------

imiKernelMLRMotionPrediction* imiKernelMLRMotionPrediction::New()
{
  return new imiKernelMLRMotionPrediction();
}

imiKernelMLRMotionPrediction::imiKernelMLRMotionPrediction()
{
  // Set default parameters:
  m_multicollinearityCheckFlag = false;
  m_TikhonovRegularizationParameter = 0.001;
  m_invCenteredK.clear();
}

// imiKernelMLRMotionPrediction::~imiKernelMLRMotionPrediction()
imiKernelMLRMotionPrediction::~imiKernelMLRMotionPrediction()
{
}

// ----------------------------
//   Public methods
// ----------------------------

// imiKernelMLRMotionPrediction::TrainLSEstimator
bool imiKernelMLRMotionPrediction::TrainLSEstimator( void )
{
  imiDEBUGINFO( 5, "-----------------------------------" );
  imiDEBUGINFO( 5, "  TRAINING OF LS ESTIMATOR" );
  imiDEBUGINFO( 5, "-----------------------------------" );

  //-------------------------------------------
  // FIRST STEP:
  // Center regressor data
  //-------------------------------------------

  if( m_regressorMatrix.empty() )
  {
    imiERROR( "KernelMLR: Regressor matrix empty! Aborting computation." );
    return false;
  }

  //-------------------------------------------
  // First STEP:
  // Center observation data
  //-------------------------------------------

  m_meanObservationVector.set_size( m_observationMatrix.rows(), 1 );
  m_meanObservationVector.fill( 0.0 );

  if( m_observationMatrix.empty() )
  {
    imiERROR( "KernelMLR: Observation matrix empty! Aborting computation." );
    return false;
  }

  // Compute mean observation vector:

  imiDEBUGINFO( 5, "  Computing mean regressand vector ... " );
  for( unsigned int i = 0; i < m_observationMatrix.rows(); i++ )
  {
    m_meanObservationVector( i, 0 ) = (m_observationMatrix.get_row( i )).mean();
  }

  // Compute mean regressand matrix entries:

  imiDEBUGINFO( 5, "  Computing regressand matrix with centered entries ... " );
  m_centeredObservationMatrix.set_size( m_observationMatrix.rows(), m_observationMatrix.cols() );
  for( unsigned int i = 0; i < m_observationMatrix.rows(); i++ )
  {
    m_centeredObservationMatrix.set_row( i, (m_observationMatrix.get_row( i ) - m_meanObservationVector( i, 0 )) );
  }

  //-------------------------------------------
  // Center regressor data
  //-------------------------------------------

  //1514.31 1513.92 1513.18 1512.02 1512.36 1512.72 1513.5
  /*m_regressorMatrix.set_size( 1, 7 );
  m_regressorMatrix.put( 0, 0, 1514.31 );
  m_regressorMatrix.put( 0, 1, 1513.92 );
  m_regressorMatrix.put( 0, 2, 1513.18 );
  m_regressorMatrix.put( 0, 3, 1512.02 );
  m_regressorMatrix.put( 0, 4, 1512.36 );
  m_regressorMatrix.put( 0, 5, 1512.72 );
  m_regressorMatrix.put( 0, 6, 1513.5 );
    m_regressorMatrix.put(1,0,3);
   m_regressorMatrix.put(1,1,4);
   m_regressorMatrix.put(1,2,3);
   m_regressorMatrix.put(1,3,2);
   m_regressorMatrix.put(1,4,4);
   m_regressorMatrix.put(1,5,7.8);
   m_regressorMatrix.put(2,0,12.8);
   m_regressorMatrix.put(2,1,1.2);
   m_regressorMatrix.put(2,2,13.3);
   m_regressorMatrix.put(2,3,1.9);
   m_regressorMatrix.put(2,4,1.2);
   m_regressorMatrix.put(2,5,0.2);*/

  // Compute mean observation vector:
  m_meanRegressorVector.set_size( m_regressorMatrix.rows(), 1 );
  m_centeredRegressorMatrix.set_size( m_regressorMatrix.rows(), m_regressorMatrix.cols() );
  m_meanRegressorVector.fill( 0.0 );

  imiDEBUGINFO( 5, "  Computing mean regressor vector ... " );
  for( unsigned int i = 0; i < m_regressorMatrix.rows(); i++ )
  {
    m_meanRegressorVector( i, 0 ) = (m_regressorMatrix.get_row( i )).mean();
  }

  // Compute mean regressand matrix entries:

  //std::cout<<"regressorMatrix: "<<m_regressorMatrix<<std::endl;

  imiDEBUGINFO( 5, "  Computing regressor matrix with centered entries ... " );
  //m_centeredObservationMatrix = m_observationMatrix;
  for( unsigned int i = 0; i < m_regressorMatrix.rows(); i++ )
  {
    m_centeredRegressorMatrix.set_row( i, (m_regressorMatrix.get_row( i ) - m_meanRegressorVector( i, 0 )) );
  }

  //std::cout<<"m_centeredRegressorMatrix: "<<m_centeredRegressorMatrix<<std::endl;

  //-------------------------------------------
  // Second STEP:
  // Compute kernel matrix
  //-------------------------------------------

  imiDEBUGINFO( 5, "  Computing kernel matrix ... " );

  m_K.set_size( m_centeredRegressorMatrix.cols(), m_centeredRegressorMatrix.cols() );

  for( unsigned int i = 0; i < m_K.rows(); i++ )
  {
    for( unsigned int j = 0; j < m_K.cols(); j++ )
    {
      //std::cout<<"dot_product: "<<m_kernel->Evaluate( m_regressorMatrix.get_column( i ), m_regressorMatrix.get_column( j ) )<<std::endl;

      m_K.put( i, j, m_kernel->Evaluate( m_centeredRegressorMatrix.get_column( i ), m_centeredRegressorMatrix.get_column( j ) ) );
    }
  }

  m_H.set_size( m_centeredRegressorMatrix.cols(), m_centeredRegressorMatrix.cols() );
  m_H.fill( -1.0 / m_centeredRegressorMatrix.cols() );
  m_H.fill_diagonal( 1.0 - (1.0 / m_centeredRegressorMatrix.cols()) );

  VnlMatrixType onesMat;
  onesMat.set_size( m_centeredRegressorMatrix.cols(), m_centeredRegressorMatrix.cols() );
  onesMat.fill( 1. / m_centeredRegressorMatrix.cols() );

  m_centeredK = m_H * m_K * m_H;
  //m_centeredK = m_K;

  imiDEBUGINFO( 5, "  Computing kernel ridge regression estimator ..." << std::endl );

  //VnlMatrixType m_centeredKCopy = m_centeredK;

  //std::cout<<"uncenteredK: "<<m_K<<std::endl;

  std::cout << "m_centeredK: " << m_centeredK << std::endl;

  /*std::cout<<"Z^+(5): "<<m_regressorMatrix.transpose()*vnl_matrix_inverse<MatrixValueType>( m_centeredRegressorMatrix*m_centeredRegressorMatrix.transpose() )<<std::endl;

   std::cout<<"Z^+(6): "<<vnl_matrix_inverse<MatrixValueType>( m_K )*m_centeredRegressorMatrix.transpose()<<std::endl;


   std::cout<<"centered"<<std::endl;

   std::cout<<"Z^+(5): "<<m_centeredRegressorMatrix.transpose()*vnl_matrix_inverse<MatrixValueType>( m_centeredRegressorMatrix*m_centeredRegressorMatrix.transpose() )<<std::endl;

   std::cout<<"Z^+(6): "<<vnl_matrix_inverse<MatrixValueType>( m_centeredRegressorMatrix.transpose()*m_centeredRegressorMatrix)*m_centeredRegressorMatrix.transpose()<<std::endl;

   std::cout<<"centeredRegressor:"<<m_centeredRegressorMatrix<<std::endl;
   std::cout<<m_centeredRegressorMatrix.transpose()*m_centeredRegressorMatrix<<std::endl;

   std::cout<<"Regressor:"<<m_regressorMatrix<<std::endl;

   std::cout<<"new centered:"<<m_K-(onesMat*m_K)-(m_K*onesMat)+(onesMat*m_K*onesMat)<<std::endl;*/

  //std::cout<<"Z^+(6): "<<vnl_matrix_inverse<MatrixValueType>( m_K )*m_regressorMatrix.transpose()<<std::endl;
  /*imiINFO("Ridge parameter: "<<m_TikhonovRegularizationParameter);

   VnlMatrixType regularizingMatrix( m_centeredKCopy.rows(), m_centeredKCopy.cols() );
   regularizingMatrix.fill( 0.0 );
   regularizingMatrix.fill_diagonal( m_TikhonovRegularizationParameter );
   m_centeredKCopy = m_centeredKCopy + regularizingMatrix;

   // Multicollinearity-check on or off?
   if( m_multicollinearityCheckFlag )
   {
   MulticollinearityCheck( m_centeredKCopy );
   }


   m_invCenteredK = vnl_matrix_inverse<MatrixValueType>( m_centeredKCopy );*/

  return true;
}

// imiKernelMLRMotionPrediction::CheckForMultiCollinearities
bool imiKernelMLRMotionPrediction::MulticollinearityCheck( VnlMatrixType& testMatrix )
{
  imiDEBUGINFO( 5, "  Checking matrix properties ... " )
  MatrixValueType conditionNumber = 0.0;

  // Preparation: Obviously, vnl rank works only for double matrices ...
  vnl_matrix<double> testMatrix_double( testMatrix.rows(), testMatrix.cols() );
  for( unsigned int i = 0; i < testMatrix.rows(); i++ )
  {
    for( unsigned int j = 0; j < testMatrix.cols(); j++ )
    {
      testMatrix_double[i][j] = static_cast<double>( testMatrix[i][j] );
    }
  }

  // FIRST TEST: Compute rank of covariance matrix.
  // If rank is not full, the matrix is (in principle) not invertible.
  // Thus, a workaround is required.

  imiDEBUGINFO( 5, "Dimension of matrix: " << testMatrix.rows() );
  unsigned int covMatrixRank = vnl_rank( testMatrix_double );
  imiDEBUGINFO( 5, "Rank of tested matrix: " << covMatrixRank );
  if( covMatrixRank < testMatrix.rows() )
  {
    conditionNumber = -1.0;
    imiWARNING( "Rank of tested matrix smaller than dimension." );
  }

  // SECOND TEST: Compute eigensystem and condition number of covariance matrix.
  // The condition number is defined as sqrt of the ratio of the largest and the smallest
  // eigenvalue of the covariance matrix. A number larger than 30 is usually assumed to
  // indicate multicollinearities (high correlation between at least two regressor variables).

  if( conditionNumber != -1.0 )
  {
    imiDEBUGINFO( 5, "Computing eigensystem: " << std::endl );
    vnl_symmetric_eigensystem<MatrixValueType> eigSystem( testMatrix );
    int testValue = 0;
    for( unsigned int i = 0; i < testMatrix.rows(); i++ )
    {
      vcl_cerr << "  " << i << "-th eigenvalue: " << eigSystem.get_eigenvalue( i ) << " (" << eigSystem.get_eigenvector( i ) << ")" << std::endl;
      if( eigSystem.get_eigenvalue( i ) < 0 )
      {
        testValue++;
      }
    }

    conditionNumber = sqrt( fabs( eigSystem.get_eigenvalue( testMatrix.rows() - 1 ) ) / fabs( eigSystem.get_eigenvalue( 0 ) ) );
    vcl_cerr << "  --> Condition number: " << conditionNumber << std::endl;

    if( conditionNumber > 30 )
    {
      imiWARNING( "Condition number > 30." );
    }
    else
    {
      imiDEBUGINFO( 5, "No multicollinearities in tested matrix!" )
      return true;
    }
  }

  // WORKAROUND in case of multicollinearities:
  // Tikhonov regularisation, i.e. AA^T --> AA^T + \lambda*E_n
  // Here we attempt to reduce the condition number to < 30 in an iterative manner.

  imiDEBUGINFO( 5, "Performing Tikhonov regularization!" );
  MatrixValueType finalTikhonovRegularizationParameter = 0.0;

  //conditionNumber=1;

  while( (conditionNumber > 30) || (conditionNumber == -1) )
  {

    //--------------------------------------------------------------------------
    //code max: for more than 500 input points -> due to performance reasons
    //          the eigensystem of the covariance matrix no longer gets checked,
    //          simply adding of 0.2 as regularization parameter

    if( testMatrix.rows() > 500 )
    {
      finalTikhonovRegularizationParameter = 0.2;
      VnlMatrixType regularizingMatrix( testMatrix.rows(), testMatrix.cols() );
      regularizingMatrix.fill( 0.0 );
      regularizingMatrix.fill_diagonal( finalTikhonovRegularizationParameter );
      testMatrix = testMatrix + regularizingMatrix;

      std::cout << " Reg-param set to 0.2 ... " << std::endl;
      std::cout << " Aborting regularization!" << std::endl;
      break;
    }

    //--------------------------------------------------------------------------

    finalTikhonovRegularizationParameter += m_TikhonovRegularizationParameter;

    VnlMatrixType regularizingMatrix( testMatrix.rows(), testMatrix.cols() );
    regularizingMatrix.fill( 0.0 );
    regularizingMatrix.fill_diagonal( m_TikhonovRegularizationParameter );

    testMatrix = testMatrix + regularizingMatrix;

    std::cout << "testmatrix: " << testMatrix << std::endl;

    // Again: computing eigensystem and condition number of updated covariance matrix:
    vnl_symmetric_eigensystem<MatrixValueType> eigSystem( testMatrix );
    conditionNumber = sqrt( fabs( eigSystem.get_eigenvalue( testMatrix.rows() - 1 ) ) / fabs( eigSystem.get_eigenvalue( 0 ) ) );

    if( finalTikhonovRegularizationParameter >= 1.0 )
    {
      std::cout << " Reg-param reached 1.0 ... " << std::endl;
      std::cout << " Condition number: " << conditionNumber << std::endl;
      std::cout << " Aborting regularization!" << std::endl;
      break;
    }
    imiINFO( "  Tikhonov regularization factor: " << finalTikhonovRegularizationParameter << "; condition number: " << conditionNumber );
  }
  vcl_cerr << "  --> Final Tikhonov regularization parameter: " << finalTikhonovRegularizationParameter << std::endl;
  return true;
}

// imiKernelMLRMotionPrediction::PredictOutput
bool imiKernelMLRMotionPrediction::PredictOutput( VnlMatrixType& regressorMeasurement, VnlMatrixType& predictedOutput )
{
  imiDEBUGINFO( 5, "  Predicting output for given regressor measurement ... " );

  imiINFO( "Ridge parameter: "<<m_TikhonovRegularizationParameter );

  if( m_invCenteredK.empty() )
  {

    VnlMatrixType m_centeredKCopy = m_centeredK;

    VnlMatrixType regularizingMatrix( m_centeredKCopy.rows(), m_centeredKCopy.cols() );
    regularizingMatrix.fill( 0.0 );
    regularizingMatrix.fill_diagonal( m_TikhonovRegularizationParameter );
    m_centeredKCopy = m_centeredKCopy + regularizingMatrix;

    m_invCenteredK = vnl_matrix_inverse<MatrixValueType>( m_centeredKCopy );

  }

  VnlMatrixType k_x;
  VnlMatrixType centeredk_x;
  VnlMatrixType ones;

  //std::cout<<"data: "<<data<<std::endl;

  ones.set_size( m_centeredRegressorMatrix.cols(), 1 );
  ones.fill( -1. / m_centeredRegressorMatrix.cols() );

  VnlMatrixType centeredMeasurement = regressorMeasurement - m_meanRegressorVector;

  k_x.set_size( m_centeredRegressorMatrix.cols(), 1 );

  for( unsigned int i = 0; i < k_x.size(); i++ )
  {
    k_x[i][0] = m_kernel->Evaluate( centeredMeasurement.get_column( 0 ), m_centeredRegressorMatrix.get_column( i ) );
  }

  centeredk_x = m_H * (k_x + (m_K * ones));
  //centeredk_x = k_x;

  predictedOutput = m_meanObservationVector + (m_centeredObservationMatrix * (m_invCenteredK * centeredk_x));

  imiDEBUGINFO( 5, "  finished."<<std::endl );
  return true;
}

// ----------------------------
//   Protected / Private methods
// ----------------------------

}// namespace imi
